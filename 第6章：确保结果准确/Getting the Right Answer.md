毋庸置疑，得到正确的结果是每一次计算的主要目的。在并行系统中，可能会遇到传统串行编程中很难遇到的问题。包括线程问题、由于浮点值计算方式导致的意外值，以及由于CPU和GPU处理器操作方式不同而产生的挑战。本章将检查可能影响返回数据正确性的问题，并指出适当的解决方案。

## 6.1. Verification
### 6.1.1. Reference Comparison
验证对任意一款现有程序修改的正确性的关键是建立一种机制，该机制可以实现将修改后的结果与修改前已知准确的结果进行比较。每当完成一次修改，都需要确保修改后的结果与修改前的结果准确一致。通常，人们会期望修改前后的结果是完全一致的，但是比如算法涉及到浮点算术运算时，这并不能总是被严格保证。有关数值计算准确性，请参见[Numerical Accuracy and Precision](https://docs.nvidia.com/cuda/archive/11.4.0/cuda-c-best-practices-guide/index.html#numerical-accuracy-and-precision).对于其他算法的修改，如果修改后的结果与修改前的参考值只在某个小的ε范围内波动，则认为该修改是正确的。

值得一提的是，用于验证数值结果的程序也能很轻易地扩展到性能验证领域。我们希望确保我们所做的每一次更改都是正确的，并且它提高了性能（以及提高了多少）。作为APOD周期性过程的一个组成部分频繁检查这些事情将有助于确保我们尽快实现期望的结果。

### 6.1.2. Unit Testing
一个与上述参考比较相辅相成的实用方法是：将代码本身组织成易于在单元级别验证的形式。例如，我们可以将CUDA内核编写为多个简短的 __device__ 函数的集合，而非一整个代码量巨大的 __global__ 函数；基于此，可以在组合到一起之前针对每个device函数进行单独的验证。

例如，许多内核除了执行计算逻辑外，还包含复杂的内存访问寻址逻辑。而若是在引入核心计算逻辑前单独验证寻址逻辑，将简化后续调试工作。（需注意：CUDA编译器会将任何未向全局内存写入数据的设备代码视为死码并予以消除，因此我们必须通过寻址逻辑向全局内存写入内容才能成功应用此策略。）

展开来说，若将大多数函数定义为 __host__ __device__ 而非仅 __device__ 函数，则可在CPU和GPU上对这些函数同步进行测试。此举既能增强函数正确性的可信度，又能避免结果出现意想不到的差异。若存在差异，也可在简单函数上下文中被及时发现和理解。

此策略还有一个附加的实用优势：若需在应用中同时包含CPU和GPU执行路径，它能减少代码重复。当CUDA内核的主要工作由 __host__ __device__ 函数完成时，我们无需重复代码即可轻松在主机代码和设备代码中调用这些函数。

## 6.2. Debugging
CUDA-GDB 是 GNU 调试器的移植版本，可在 Linux 和 Mac 系统上运行；详见：https://developer.nvidia.com/cuda-gdb。

NVIDIA Nsight Visual Studio Edition 适用于 Microsoft Windows 7、Windows HPC Server 2008、Windows 8.1 和 Windows 10，可作为 Microsoft Visual Studio 的免费插件使用；详见：https://developer.nvidia.com/nsight-visual-studio-edition。

众多第三方调试器同样支持 CUDA 调试；更多详情参见：https://developer.nvidia.com/debugging-solutions。

## 6.3. Numerical Accuracy and Precision
不正确或意外的结果主要源于浮点数的精度问题，主要与该类型值的计算和存储方式有关。接下来的章节将重点解释。浮点运算的其他特性可以在《CUDA C++编程指南》的"特性与技术规范"部分查看，也可以通过白皮书和相关网络研讨会了解，这些资源讨论了浮点精度和性能问题，访问地址是：
http://developer.nvidia.com/content/precision-performance-floating-point-and-ieee-754-compliance-nvidia-gpus

### 6.3.1. Single vs. Double Precision
计算能力1.3及以上的设备原生支持双精度浮点值（即64位宽数值）。由于双精度运算具有更高精度且涉及舍入问题，其计算结果常与单精度算术执行的相同运算存在差异。因此，应该确保是对相同精度的数值进行比较，并在特定容差范围内表示结果，而非期望结果完全精确。

### 6.3.2. Floating Point Math Is not Associative
每个浮点算术运算都涉及一定程度的舍入。因此，算术运算的执行顺序至关重要。若 A、B 和 C 是浮点数值，(A+B)+C 并不保证会等于 A+(B+C)，这与符号数学中的情况不同。当您将计算并行化时，可能会改变运算顺序，从而导致并行结果与串行结果不匹配。这种限制并非 CUDA 特有，而是浮点数值并行计算固有的特性。

### 6.3.3. IEEE 754 Compliance
所有 CUDA 计算设备均遵循 IEEE 754 二进制浮点表示标准，但存在少量例外情况。这些例外在《CUDA C++ 编程指南》的"特性与技术规范"部分有详细说明，而在这些情况下，可能导致计算结果与主机系统上计算的 IEEE 754 标准值存在差异。

其中一个关键差异是融合乘加（FMA）指令，该指令将乘法-加法运算合并为单条指令执行。其计算结果通常与分别执行两项操作获得的结果略有不同。

### 6.3.4. x86 80-bit Computations
x86 处理器在执行浮点计算时可以使用 80 位双扩展精度数学运算。这些计算结果常常与在 CUDA 设备上执行的纯 64 位运算结果不同。要使数值更接近，可将 x86 主机处理器设置为使用常规双精度或单精度（分别为 64 位和 32 位）。这可通过 FLDCW x86 汇编指令或等效的操作系统 API 实现。