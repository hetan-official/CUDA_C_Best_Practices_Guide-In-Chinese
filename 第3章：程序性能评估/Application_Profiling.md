# 3.1 Profile
现实中与有不少情况是：很多程序中的核心功能可能仅数十行或者数百行就得以实现了。使用程序性能分析工具，开发人员能够识别出这部分热点代码，并为该部分代码的并行化编制候选方案。

## 3.1.1 Creating the Profile
如今已经有许多可行的方式可以用于测试代码的性能，但总归，所有的方案最终目的都是一样的：即识别出应用程序中那些最耗时的函数或者函数们。

**高优先级**：为了最大化开发人员的开发价值，测试应用程序性能以找出热点代码和性能瓶颈。

翻译：任何性能分析动作最重要的考量都是确保工作负载是符合实际情况的，比如，在测试环节和决策环节所采纳的信息都应该是来自于真实场景的信息。采用虚假的数据会导致sub-optimal问题和让开发人员在和真实不符的问题边界以及非瓶颈的函数上浪费过多的时间。

有许多性能分析工具可以用来满足我们的需求，下文给出的是一个Linux平台下来源于GNU内建指令集的开源profiler：[gprof]
```bash
$ gcc -O2 -g -pg myprog.c
$ gprof ./a.out > profile.txt
Each sample counts as 0.01 seconds.
  %   cumulative   self              self     total           
 time   seconds   seconds    calls  ms/call  ms/call  name    
 33.34      0.02     0.02     7208     0.00     0.00  genTimeStep
 16.67      0.03     0.01      240     0.04     0.12  calcStats
 16.67      0.04     0.01        8     1.25     1.25  calcSummaryData
 16.67      0.05     0.01        7     1.43     1.43  write
 16.67      0.06     0.01                             mcount
  0.00      0.06     0.00      236     0.00     0.00  tzset
  0.00      0.06     0.00      192     0.00     0.00  tolower
  0.00      0.06     0.00       47     0.00     0.00  strlen
  0.00      0.06     0.00       45     0.00     0.00  strchr
  0.00      0.06     0.00        1     0.00    50.00  main
  0.00      0.06     0.00        1     0.00     0.00  memcpy
  0.00      0.06     0.00        1     0.00    10.11  print
  0.00      0.06     0.00        1     0.00     0.00  profil
  0.00      0.06     0.00        1     0.00    50.00  report
```

## 3.1.2 Identifying Hostpots
上边的例子中，一眼便可发现函数[genTimeStep]用时占据了应用程序总耗时的1/3。因此，这个函数应该作为我们程序并行化时首先需要考虑的函数。[Understanding Scaling]()小节会对我们进行并行化带来的潜在收益进行讨论。

对上述例子进一步分析可以发现，如[calcStats()]和[calcSummaryData()]函数也在程序用时上有相当的占比。对这些函数进行并行化的改写将释放我们的程序的加速潜能。然而，由于APOD是一个循环往复的过程，我们应该在随后的APOD流程中逐步并行化这些函数，以将我们工作的范围限定在局部，避免在一次APOD流程中对程序整体做大幅度的变更。

### 3.1.3 Understanding Scaling
应用程序在CUDA上运行时的性能完全取决于其并行化的程度。原则上来说，无法充分并行化的代码应该规划到host上运行，当然也有例外情况，就是这样做会导致host和device之间传输过多的数据，这种情况需要注意。

**High Priority**: 为了最大化发挥CUDA的性能，首先将注意力放到提升串行代码的并行度上。

通过理解应用程序的Scaling过程，可以在开发过程中指定相应的期望和一个循序渐进的并行化方案。[Strong Scaling and Amdahl's Law]小节介绍了我们在给定的问题范围内可以达到的加速比上限。[Weaking Scaling and Gustafson's Law]则描述了随着问题规模的增长，可以获得的加速比的情况。在许多应用程序的开发中需要综合考虑强和弱Scaling。

#### 3.1.3.1 Strong Scaling and Amdahl's Law
Strong Scaling所描述的是，在给定的问题范围的情况下，随着向系统中增加越来越多的处理器，解决问题的时间的下降程度。一个具有Strong Scaling属性的应用程序，其加速比和所投入的线程数量呈线性关系。通常情况下，Strong Scaling说的就是描述在串行编程中通过并行其中一部分代码所能达到的最大加速比规律的Amdahl's Law。其重点是，程序的最大加速比S表示为：

![Amdahl's Law](https://github.com/user-attachments/assets/997e1815-1028-44fc-b1e7-7baad5c76e14)

式中P表示程序总共运行时间中被并行那部分代码在串行情况下所用的时间，N则是并行执行部分代码所启动的线程数量。N的值越大（也即并行执行代码调用的处理器越多），P/N的值就越小。很显然，当N是一个趋于无穷大的数时，上式等价于S = 1 / (1 - P)。举个例子，比如现在在串行程序中3/4的代码都得以并行化了，那么这个程序的加速比就会达到1 / (1 - 3/4) = 4倍。

真实环境中，大部分的应用程序都不会与Strong Scaling有特别好的一致性，哪怕是在某种程度上，有的程序与这一规律是符合的。通常情况下，并行部分P越大，潜在的加速比也会越大。与之相反的是，如果P是一个小数（意味着应用程序没有得到良好的并行化的情况）的情况下，简单增加处理器的数量N对提升程序性能基本是徒劳的。因此，为了实现给定问题规模下最大加速比，很有必要通过尽可能多地并行化代码来尽可能最大化P的值。

#### 3.1.3.2. Weak Scaling and Gustafson's Law
Weak scaling描述的是如果每个处理器所需要处理的问题规模是一定的，随着系统中引入越来越多的处理器，解决问题的时间将会如何变化。即，单个处理器的负载不变，随着处理器的增加，问题规模也随之增加时总体时间的变化规律。

Weak Scaling通常等同于Gustafson's Law。这一定律刻画的是，真实情况下，问题规模伴随处理器数量的变化情况。基于此，最大加速比S可以表示为：
![Weak Scaling](https://github.com/user-attachments/assets/d43ac3db-6afc-4865-8875-d022b776b2cb)

式中P和N的含义与Amdahl's Law中的一样。对Gustafson's Law可以这么理解，执行时间一定的情况下，如果系统中引入的处理器数量发生了变化，那么问题规模也会随之发生变化。需要注意的是，该定律假设程序中串行与并行部分比例上保持不变以反映在更大规模问题的处置上会额外引入的开销。

#### 3.1.3.3. Appling Strong and Weak Scaling
理解需要采用哪种Scaling策略是估算加速比流程中重要的一环。对于某些问题，问题规模是恒定不变的，因此采用Strong Scaling方案是可行的，比如说对于描述两个分子之间相互作用的模型，分子的大小固定不变的情形。

而对于另外一些问题，为了充分利用所有可用的处理器，问题的规模会不断增长。比如说将流体或者结构以Mesh或者Grid建模的Monte Carlo仿真问题，增加问题的规模将有助于提升问题求解的精确性。

在充分理解了应用程序所面向的问题的特征后，开发人员应该清楚如果计算性能发生了变化，问题的规模将随之如何变化。随后，可借助Amdahl's Law或者Gustafson's Law来确定加速比的潜在上限。
