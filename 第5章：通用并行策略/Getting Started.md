# Getting Started
如今，关于串行化代码已经有很多可用的策略。虽然，针对具体的应用程序如何才能有效施展这些策略仍然是一个复杂且需要因地制宜的问题，但是在本章节中所介绍的策略，却是无论在CPU还是支持CUDA的GPU架构上都是适用的。

## 5.1. Parallel Libraries
并行化应用程序一个最直给的方案是充分应用NVIDIA提供的经过优化的库。CUDA Toolkit已经包含了许多针对NVIDIA CUDA GPUs的并行库，比如[cuBLAS]，[cuFFT]等等。

能有效利用这些库的关键是充分理解程序本身的需求，将其与库的功能有效匹配。如果程序本身已经使用了BLAS库，那么很轻易就可以切换到[cuBLAS]库，与此相反，如果程序本身几乎没有线性代数类的操作，那么调用[cuBLAS]库大概率收效甚微。这一点在CUDA Toolkit自带的其他库中也是一样，比如[cuFFT]与FFTW库的功能就非常相似。

这里需要着重介绍的是Thrust库，一个类似于C++ STL的并行模板库。Thrust提供了丰富的数据并行操作原语，如scan, sort和reduce，可供用户以简洁和方便阅读的源代码组合起来实现复杂的算法。将你所面对的问题以这些高层次的抽象来描述，Thrust库能高效且自动地在算法中进行选择。基于此，Thrust可以作为你的CUDA应用程序快速开发的一个原型，这将在鲁棒性和性能都十分重要的生产环境下使您受益。

## 5.2. Parallelizing Compilers
另一种常见的使串行指令并行化的方法时使用并行化编译器。通常，这意味着使用基于预编译指令的方法，程序员通过预编译指令建议编译器将模型指令并行化，而无需对代码本身进行改动。通过向编译器暴露代码的并行性，指令将完成使编译器将计算映射到并行架构的一系列工作。OpenACC标准提供了一组编译器指令，可作用于标准C、C++和Fortran代码中的循环和特定代码片段，这些代码片段在被映射后将会在系统的加速硬件（例如CUDA GPU）而非CPU上运行。管理加速device的详细过程由支持OpenACC的编译器和运行时隐式处理。

更多细节请点击：https://www.openacc.org/

## 5.3. Coding to Expose Parallelism
对于那些具有现有并行库或并行化编译器无法支持的功能或者性能要求的应用程序而言，将现有的串行代码无缝集成到并行编程语言（如CUDA C）非常重要。一旦通过评估应用程序的性能分析输出，定位到了hotspot代码，就可以因地制宜地利用CUDA C将这部分代码改写为并行化的CUDA kernel函数。伺候，便可以在CPU端启动kernel函数并使其在GPU上运行并检索结果，且无需大规模重写程序的剩余部分。当应用程序总运行时间的大部分花费在几个相对独立的代码部分时，这种方法最直接。更为困难的情况是，性能评估文件显示出程序的运行时间均布在程序中大量的函数上。针对这种情况，可能需要一定程度上重构程序代码以暴露出程序中潜在的并行性，但是请记住，虽然重构工作千头万绪，其收获却是可观的。这样的重构使得程序对未来的架构更兼容，无论是CPU还是GPU。所以，如果有必要，这些努力都值得。